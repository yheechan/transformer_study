{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pprint\n",
    "\n",
    "import torch, gc\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from data_loader import DataLoader\n",
    "import data_loader\n",
    "import trainer\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "from models.transformer import Transformer\n",
    "import model_util as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, output_size, \n",
    "    hidden_size=32,\n",
    "    n_splits=8,\n",
    "    n_layers=4,\n",
    "    dropout=0.0,\n",
    "    use_transformer=True):\n",
    "\n",
    "\tif use_transformer:\n",
    "\t\tmodel = Transformer(\n",
    "\t\t\tinput_size,\t\t\t\t\t\t# Source vocabulary size\n",
    "\t\t\thidden_size,\t\t\t\t# Transformer doesn't need word_vec_size,\n",
    "\t\t\toutput_size,\t\t\t\t\t# Target vocabulary size\n",
    "\t\t\tn_splits=n_splits,\t\t# Number of head in Multi-head Attention\n",
    "\t\t\tn_enc_blocks=n_layers,\t# number of encoder blocks\n",
    "\t\t\tn_dec_blocks=n_layers,\t# Number of decoder blocks\n",
    "\t\t\tdropout_p=dropout,\t\t# Dropout rate on each block\n",
    "\t\t)\n",
    "\telse:\n",
    "\t\tmodel = Transformer(\n",
    "\t\t\tinput_size,\t\t\t\t\t\t# Source vocabulary size\n",
    "\t\t\thidden_size,\t\t\t\t# Transformer doesn't need word_vec_size,\n",
    "\t\t\toutput_size,\t\t\t\t\t# Target vocabulary size\n",
    "\t\t\tn_splits=n_splits,\t\t# Number of head in Multi-head Attention\n",
    "\t\t\tn_enc_blocks=n_layers,\t# number of encoder blocks\n",
    "\t\t\tn_dec_blocks=n_layers,\t# Number of decoder blocks\n",
    "\t\t\tdropout_p=dropout,\t\t# Dropout rate on each block\n",
    "\t\t)\n",
    "\t\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def get_crit(output_size, pad_index):\n",
    "\t# Default weight for loss equals to 1, but we don't need to get loss for PAD token\n",
    "\t# Thus, set a weight for PAD to zero.\n",
    "\tloss_weight = torch.ones(output_size)\n",
    "\tloss_weight[pad_index] = 0.\n",
    "\n",
    "\t# Instead of using Cross-Entropy Loss,\n",
    "\t# we can use Negative Log-Likelihood(NLL) Loss with log-probability.\n",
    "\tprint('\\n Loss function: Negative Log-Likelihood with log-probability (NLLLoss)')\n",
    "\tcrit = nn.NLLLoss(\n",
    "\t\tweight=loss_weight,\n",
    "\t\treduction='sum',\n",
    "\t)\n",
    "\n",
    "\treturn crit\n",
    "\n",
    "\n",
    "def get_optimizer(model, \n",
    "    use_adam=True,\n",
    "    use_transformer=True,\n",
    "    lr=0.0001,):\n",
    "\tif use_adam:\n",
    "\t\tif use_transformer:\n",
    "\t\t\toptimizer = optim.Adam(model.parameters(), lr=lr, betas=(.9, .98))\n",
    "\t\telse: # case of rnn based seq2seq\n",
    "\t\t\toptimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\telse:\n",
    "\t\tprint('Optimizer: Adam')\n",
    "\t\toptimizer = optim.Adam(model.parameters(), lr=lr, betas=(.9, .98))\n",
    "\t\n",
    "\treturn optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "        'corpus.shuf.train.tok.bpe',\n",
    "        'corpus.shuf.val.tok.bpe',\n",
    "        ('en', 'ko'),                           # Source and target language.\n",
    "        batch_size=8,\n",
    "        device=-1,                              # Lazy loading\n",
    "        max_length=50,                          # Loger sequence will be excluded.\n",
    "        dsl=False,                              # Turn-off Dual-supervised Learning mode.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, output_size = len(loader.src.vocab), len(loader.tgt.vocab)\n",
    "print('\\ninput_size: ', input_size)\n",
    "print('output_size: ', output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(input_size, output_size)\n",
    "print('\\n', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = get_crit(output_size, data_loader.PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model_weight is not None:\n",
    "    # model.load_state_dict(model_weight)\n",
    "\n",
    "# check for available gpu\n",
    "if torch.cuda.is_available():\n",
    "    device_num = 0\n",
    "    print('\\nUsing device number: 0')\n",
    "else:\n",
    "    device_num = -1\n",
    "    print('\\nUsing device number: -1')\n",
    "\n",
    "# Clear memory cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Pass model to GPU device if it is necessary\n",
    "if device_num >= 0:\n",
    "    model.cuda(device_num)\n",
    "    crit.cuda(device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if opt_weight is not None and config.use_adam:\n",
    "    # optimizer.load_state_dict(opt_weight)\n",
    "\n",
    "lr_schedular = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_title = 'local'\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('./tensorboard/'+overall_title+'/tests')\n",
    "\n",
    "title = overall_title + '_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    model,\n",
    "    crit,\n",
    "    optimizer,\n",
    "    train_loader=loader.train_iter,\n",
    "    valid_loader=loader.valid_iter,\n",
    "    src_vocab=loader.src.vocab,\n",
    "    tgt_vocab=loader.tgt.vocab,\n",
    "    n_epochs=20,\n",
    "    lr_schedular=lr_schedular,\n",
    "    writer=writer,\n",
    "    title=title,\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(overall_title, title, model)\n",
    "# mu.graphModel(train_dataloader, model, writer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mu.getModel(overall_title, title)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
