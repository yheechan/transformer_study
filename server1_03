using data from torchtext.legacy
{   'batch_size': 64,
    'dropout': 0.2,
    'hidden_size': 512,
    'lang': 'enko',
    'lr': 0.0003,
    'max_length': 25,
    'n_epochs': 50,
    'n_layers': 4,
    'n_splits': 8,
    'train': 'corpus.shuf.train.tok.bpe',
    'use_adam': False,
    'use_transformer': True,
    'valid': 'corpus.shuf.valid.tok.bpe'}
